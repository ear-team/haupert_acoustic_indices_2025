{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute acoustic indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated 20 October 2025\n",
      "Author: Sylvain Haupert\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Updated 20 October 2025\n",
    "Author: Sylvain Haupert\n",
    "\"\"\"\n",
    "\n",
    "from IPython import get_ipython\n",
    "print(__doc__)\n",
    "\n",
    "# Clear all the variables\n",
    "get_ipython().run_line_magic('reset', '-sf')\n",
    "\n",
    "# suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Parallel processing packages\n",
    "from tqdm import tqdm\n",
    "from concurrent import futures\n",
    "\n",
    "# maad package to process the sound and extract the acoustic indices\n",
    "from maad import sound, features, util\n",
    "\n",
    "# Import configuration file\n",
    "import sys\n",
    "sys.path.append(str(Path('../src')))\n",
    "import config as cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Notebook init and options setting\n",
    "\n",
    "* Select the option and the configuration file\n",
    "* init the local function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"==============================================================================\n",
    "    options             \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "PROCESS_DATA = True\n",
    "SAVE = True\n",
    "DISPLAY = True\n",
    "VERBOSE = False\n",
    "CONFIG = cfg.load_config('config_publication.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"==============================================================================\n",
    "    local function to compute acoustic indices \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "def single_file_processing(audio_full_filename, date_time):\n",
    "    \"\"\"\n",
    "    Compute acoustic indices for a single audio file.\n",
    "\n",
    "    Summary of the steps:\n",
    "    ---------------------\n",
    "    - load the sound file\n",
    "    - resample the sound to the target sampling frequency\n",
    "    - bandpass filter the sound between flim_min and flim_max\n",
    "    - trim the sound between tlim_min and tlim_max\n",
    "    - compute temporal indices\n",
    "    - compute spectral indices\n",
    "    - create a dataframe with all the indices\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_full_filename : str\n",
    "        Full path to the audio file.\n",
    "    date_time : str\n",
    "        Date and time associated with the audio file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_indices : pandas.DataFrame\n",
    "        DataFrame containing the computed acoustic indices.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    _, filename_with_ext = os.path.split(audio_full_filename)\n",
    "    file = os.path.splitext(filename_with_ext)[0]\n",
    "\n",
    "    # Load the original sound (16bits) and get the sampling frequency fs\n",
    "    try:\n",
    "        wave, fs = sound.load(\n",
    "            filename=audio_full_filename,\n",
    "            channel=CONFIG['channel'], \n",
    "            detrend=True, \n",
    "            verbose=False\n",
    "            )\n",
    "        \n",
    "        # resample to SAMPLING_FREQUENCY and update fs\n",
    "        wave = sound.resample(\n",
    "            s=wave,\n",
    "            fs=fs,\n",
    "            target_fs=CONFIG['sampling_frequency'],\n",
    "            )\n",
    "        fs = CONFIG['sampling_frequency']\n",
    "        duration = len(wave) / fs\n",
    "\n",
    "        # bandpass filter between BW_FREQ_MIN and BW_FREQ_MAX\n",
    "        if (DATASET['flim_min'] is not None) and (DATASET['flim_max'] is not None):   \n",
    "            wave = sound.select_bandwidth(\n",
    "                x=wave, \n",
    "                fs=fs, \n",
    "                fcut=(DATASET['flim_min'],DATASET['flim_max'] ), \n",
    "                forder = 5,\n",
    "                ftype='bandpass')\n",
    "        elif DATASET['flim_max'] is not None:\n",
    "            wave = sound.select_bandwidth(\n",
    "                x=wave, \n",
    "                fs=fs, \n",
    "                fcut=(DATASET['flim_max']), \n",
    "                forder = 5,\n",
    "                ftype='low')\n",
    "        elif DATASET['flim_min'] is not None :\n",
    "            wave = sound.select_bandwidth(\n",
    "                x=wave, \n",
    "                fs=fs, \n",
    "                fcut=(DATASET['flim_min']), \n",
    "                forder = 5,\n",
    "                ftype='high')\n",
    "        \n",
    "        # trim\n",
    "        if (DATASET['tlim_min'] is not None) and (DATASET['tlim_max'] is not None):\n",
    "            wave = sound.trim(\n",
    "                s=wave, \n",
    "                fs=fs,\n",
    "                min_t=DATASET['tlim_min'],\n",
    "                max_t=DATASET['tlim_max'] )\n",
    "        elif (DATASET['tlim_min'] is not None):\n",
    "            wave = sound.trim(\n",
    "                s=wave, \n",
    "                fs=fs,\n",
    "                min_t=DATASET['tlim_min'],\n",
    "                max_t=duration)\n",
    "        elif (DATASET['tlim_max'] is not None):\n",
    "            wave = sound.trim(\n",
    "                s=wave, \n",
    "                fs=fs,\n",
    "                min_t=0,\n",
    "                max_t=DATASET['tlim_max'] )\n",
    "\n",
    "        \"\"\" ===================================================================\n",
    "                        Computation in the time domain \n",
    "        ===================================================================\"\"\"\n",
    "\n",
    "        # compute all the audio indices and store them into a DataFrame\n",
    "        # dB_threshold and rejectDuration are used to select audio events.\n",
    "        df_audio_ind = features.all_temporal_alpha_indices(\n",
    "            wave, fs,\n",
    "            mode=CONFIG['mode_env'],\n",
    "            Nt=CONFIG['Nt'],\n",
    "            gain=CONFIG['gain'],\n",
    "            sensibility=CONFIG['sensibility'],\n",
    "            Vadc=CONFIG['sensibility'],\n",
    "            dt=CONFIG['deltaT'],\n",
    "            dB_threshold=CONFIG['dB_threshold'],\n",
    "            rejectDuration=CONFIG['reject_duration'],\n",
    "            verbose=VERBOSE,\n",
    "            display=False\n",
    "            )\n",
    "\n",
    "        # Test if the audio clip\n",
    "        if ((wave.max() >= 0.99) or (wave.min() <= -0.99)):\n",
    "            clip = 1\n",
    "        else:\n",
    "            clip = 0\n",
    "            \n",
    "        df_audio_ind.insert(\n",
    "            loc=0, \n",
    "            column='clipping', \n",
    "            value=clip\n",
    "            )\n",
    "        \n",
    "        df_audio_ind.insert(\n",
    "            loc=1, \n",
    "            column='audio_duration', \n",
    "            value=len(wave) / fs /60\n",
    "            )\n",
    "\n",
    "        \"\"\" ==================================================================\n",
    "                        Computation in the frequency domain \n",
    "        ===================================================================\"\"\"\n",
    "\n",
    "        # Compute the Power Spectrogram Density (PSD) : Sxx_power\n",
    "        Sxx_power, tn, fn, ext = sound.spectrogram(\n",
    "            wave,fs,\n",
    "            window=CONFIG['window'],\n",
    "            nperseg=CONFIG['n_fft'],\n",
    "            noverlap=CONFIG['hop_length'],\n",
    "            verbose=VERBOSE,\n",
    "            display=False,\n",
    "            savefig=None)\n",
    "\n",
    "        # compute all the spectral indices and store them into a DataFrame\n",
    "        # flim_low, flim_mid, flim_hi corresponds to the frequency limits in Hz\n",
    "        # that are required to compute somes indices (i.e. NDSI)\n",
    "        # if R_compatible is set to 'soundecology', then the output is similar to\n",
    "        # soundecology R package.\n",
    "        df_spec_ind, _ = features.all_spectral_alpha_indices(\n",
    "            Sxx_power,\n",
    "            tn, fn,\n",
    "            flim_low=CONFIG['flim_low'],\n",
    "            flim_mid=CONFIG['flim_mid'],\n",
    "            flim_hi=CONFIG['flim_hi'],\n",
    "            R_compatible='soundecology',\n",
    "            seed_level=CONFIG['seed_level'], \n",
    "            low_level=CONFIG['low_level'], \n",
    "            fusion_rois=CONFIG['fusion_rois'],\n",
    "            remove_rois_flim_min = CONFIG['remove_rois_flim_min'],\n",
    "            remove_rois_flim_max = CONFIG['remove_rois_flim_max'],\n",
    "            remove_rain = CONFIG['remove_rain'],\n",
    "            min_event_duration=CONFIG['min_event_duration'], \n",
    "            max_event_duration=CONFIG['max_event_duration'], \n",
    "            min_freq_bw=CONFIG['min_freq_bw'], \n",
    "            max_freq_bw=CONFIG['max_freq_bw'], \n",
    "            max_ratio_xy = CONFIG['max_ratio_xy'],\n",
    "            verbose=VERBOSE,\n",
    "            display=False)\n",
    "\n",
    "        \"\"\" ===================================================================\n",
    "                        Create a dataframe \n",
    "        ====================================================================\"\"\"        \n",
    "        # add scalar indices into the df_indices dataframe\n",
    "        df_indices = pd.concat([df_audio_ind,\n",
    "                                df_spec_ind], axis=1)\n",
    "\n",
    "        # add date and audio_path\n",
    "        df_indices.insert(0, 'Date', date_time)\n",
    "        df_indices.insert(1, 'file', audio_full_filename)\n",
    "    \n",
    "    except:\n",
    "        # create a new dataframe with the column Date and file\n",
    "        df_indices = pd.DataFrame({'Date': [date_time], 'fullfilename': [audio_full_filename], 'file': [file]})\n",
    "\n",
    "    return df_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"==============================================================================\n",
    "    Main loop to process all 1-min soundscapes\n",
    "    ------------------------------------------\n",
    "\n",
    "    Summary of the steps:\n",
    "    ---------------------\n",
    "    - for each dataset in the configuration file:\n",
    "        - prepare the configuration for the dataset\n",
    "        - parse a directory in order to get a df with date and fullfilename\n",
    "        - Multi CPU processing to compute acoustic indices for each audio file\n",
    "        - save the dataframe with all indices\n",
    "        \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "if PROCESS_DATA :\n",
    "\n",
    "    for DATASET in CONFIG['datasets']:\n",
    "\n",
    "        \"\"\" ===========================================================================\n",
    "                        Prepare the configuration for the dataset\n",
    "        ============================================================================\"\"\"\n",
    "        \n",
    "        # test if audio_extension exists in the dataset configuration\n",
    "        if 'audio_extension' not in DATASET.keys():\n",
    "            DATASET['audio_extension'] = CONFIG['audio_extension']\n",
    "\n",
    "        # display the dataset name\n",
    "        display(f'Dataset {DATASET[\"name\"]} is being processed...')\n",
    "        # parse a directory in order to get a df with date and fullfilename\n",
    "        df = util.date_parser(\n",
    "                        datadir=DATASET['path'], \n",
    "                        dateformat=DATASET['datetime_format'], \n",
    "                        extension=DATASET['audio_extension'],\n",
    "                        verbose=False)\n",
    "        # Date is used as index. Reset the index in order to get back Date as column\n",
    "        df.reset_index(inplace = True)\n",
    "        # number of files to process\n",
    "        display('{} files will be processed'.format(len(df)))\n",
    "    \n",
    "        \"\"\" ===========================================================================\n",
    "                        Multi CPU\n",
    "        ============================================================================\"\"\"\n",
    "        # At least 2 CPUs will be used in parallel and the files to process will be \n",
    "        # distributed on each CPU depending on their availability. This will speed up\n",
    "        # the process.\n",
    "\n",
    "        # create an empty dataframe. It will contain all indices for each\n",
    "        # audio file in the directory\n",
    "        df_indices = pd.DataFrame()\n",
    "\n",
    "        # create an empty dataframe. It will contain files that failed\n",
    "        df_failed = pd.DataFrame()\n",
    "\n",
    "        # Number of CPU used for the calculation. \n",
    "        nb_cpu = np.max([2, os.cpu_count()])\n",
    "\n",
    "        tic = time.perf_counter()\n",
    "        # Multicpu process\n",
    "        with tqdm(total=len(df), desc=\"multi cpu indices calculation...\") as pbar:\n",
    "            with futures.ProcessPoolExecutor(max_workers=nb_cpu-1) as pool:\n",
    "                # give the function to map on several CPUs as well its arguments as \n",
    "                # as list\n",
    "                for df_indices_temp in pool.map(\n",
    "                        single_file_processing, \n",
    "                        df[\"file\"].to_list(), \n",
    "                        df[\"Date\"].to_list()\n",
    "                        ):\n",
    "                    pbar.update(1)\n",
    "                    # test the number of columns. If only two, the process failed for the audio file\n",
    "                    if len(df_indices_temp.columns) == 3:\n",
    "                        df_failed = pd.concat([df_failed, df_indices_temp], axis=0)\n",
    "                    else :\n",
    "                        df_indices = pd.concat([df_indices, df_indices_temp], axis=0)\n",
    "        \n",
    "        df_indices.set_index('Date', inplace=True)\n",
    "        \n",
    "        toc = time.perf_counter()\n",
    "        \n",
    "        # time duration of the process\n",
    "        multicpu_duration = toc - tic\n",
    "\n",
    "        print(f\"Elapsed time is {multicpu_duration:0.1f} seconds\")\n",
    "\n",
    "        # display the files that failed to be processed (df_failed)\n",
    "        print(f\"The number of audio files that failed to be processes is {len(df_failed)}\")\n",
    "        display(df_failed)\n",
    "\n",
    "        if SAVE == True:\n",
    "            # save df_indices\n",
    "            df_indices.to_csv(\n",
    "                            path_or_buf=os.path.join(\n",
    "                                                CONFIG['save_dir'], \n",
    "                                                'indices_'+DATASET['name']+'_BW'+str(DATASET['flim_min'])+'Hz_'+str(DATASET['flim_max'])+'Hz_'+str(CONFIG['seed_level'])+'db'+'.csv'), \n",
    "                            sep=',', \n",
    "                            mode='w', \n",
    "                            header=True, \n",
    "                            index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ear-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
