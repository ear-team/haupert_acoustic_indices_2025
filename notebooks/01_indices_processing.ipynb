{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute acoustic indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated 20 October 2025\n",
      "Author: Sylvain Haupert\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Updated 20 October 2025\n",
    "Author: Sylvain Haupert\n",
    "\"\"\"\n",
    "\n",
    "from IPython import get_ipython\n",
    "print(__doc__)\n",
    "\n",
    "# Clear all the variables\n",
    "get_ipython().run_line_magic('reset', '-sf')\n",
    "\n",
    "# suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Parallel processing packages\n",
    "from tqdm import tqdm\n",
    "from concurrent import futures\n",
    "\n",
    "# maad package to process the sound and extract the acoustic indices\n",
    "from maad import sound, features, util\n",
    "\n",
    "# Import configuration file\n",
    "import sys\n",
    "sys.path.append(str(Path('../src')))\n",
    "import config as cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Notebook init\n",
    "\n",
    "* init the local function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"==============================================================================\n",
    "    local function to compute acoustic indices \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "def single_file_processing(audio_full_filename, date_time):\n",
    "    \"\"\"\n",
    "    Compute acoustic indices for a single audio file.\n",
    "\n",
    "    Summary of the steps:\n",
    "    ---------------------\n",
    "    - load the sound file\n",
    "    - resample the sound to the target sampling frequency\n",
    "    - bandpass filter the sound between flim_min and flim_max\n",
    "    - trim the sound between tlim_min and tlim_max\n",
    "    - compute temporal indices\n",
    "    - compute spectral indices\n",
    "    - create a dataframe with all the indices\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_full_filename : str\n",
    "        Full path to the audio file.\n",
    "    date_time : str\n",
    "        Date and time associated with the audio file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_indices : pandas.DataFrame\n",
    "        DataFrame containing the computed acoustic indices.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    _, filename_with_ext = os.path.split(audio_full_filename)\n",
    "    file = os.path.splitext(filename_with_ext)[0]\n",
    "\n",
    "    # Load the original sound (16bits) and get the sampling frequency fs\n",
    "    try:\n",
    "        wave, fs = sound.load(\n",
    "            filename=audio_full_filename,\n",
    "            channel=CONFIG['channel'], \n",
    "            detrend=True, \n",
    "            verbose=False\n",
    "            )\n",
    "        \n",
    "        # resample to SAMPLING_FREQUENCY and update fs\n",
    "        wave = sound.resample(\n",
    "            s=wave,\n",
    "            fs=fs,\n",
    "            target_fs=CONFIG['sampling_frequency'],\n",
    "            )\n",
    "        fs = CONFIG['sampling_frequency']\n",
    "        duration = len(wave) / fs\n",
    "\n",
    "        # bandpass filter between BW_FREQ_MIN and BW_FREQ_MAX\n",
    "        if (DATASET['flim_min'] is not None) and (DATASET['flim_max'] is not None):   \n",
    "            wave = sound.select_bandwidth(\n",
    "                x=wave, \n",
    "                fs=fs, \n",
    "                fcut=(DATASET['flim_min'],DATASET['flim_max'] ), \n",
    "                forder = 5,\n",
    "                ftype='bandpass')\n",
    "        elif DATASET['flim_max'] is not None:\n",
    "            wave = sound.select_bandwidth(\n",
    "                x=wave, \n",
    "                fs=fs, \n",
    "                fcut=(DATASET['flim_max']), \n",
    "                forder = 5,\n",
    "                ftype='low')\n",
    "        elif DATASET['flim_min'] is not None :\n",
    "            wave = sound.select_bandwidth(\n",
    "                x=wave, \n",
    "                fs=fs, \n",
    "                fcut=(DATASET['flim_min']), \n",
    "                forder = 5,\n",
    "                ftype='high')\n",
    "        \n",
    "        # trim\n",
    "        if (DATASET['tlim_min'] is not None) and (DATASET['tlim_max'] is not None):\n",
    "            wave = sound.trim(\n",
    "                s=wave, \n",
    "                fs=fs,\n",
    "                min_t=DATASET['tlim_min'],\n",
    "                max_t=DATASET['tlim_max'] )\n",
    "        elif (DATASET['tlim_min'] is not None):\n",
    "            wave = sound.trim(\n",
    "                s=wave, \n",
    "                fs=fs,\n",
    "                min_t=DATASET['tlim_min'],\n",
    "                max_t=duration)\n",
    "        elif (DATASET['tlim_max'] is not None):\n",
    "            wave = sound.trim(\n",
    "                s=wave, \n",
    "                fs=fs,\n",
    "                min_t=0,\n",
    "                max_t=DATASET['tlim_max'] )\n",
    "\n",
    "        \"\"\" ===================================================================\n",
    "                        Computation in the time domain \n",
    "        ===================================================================\"\"\"\n",
    "\n",
    "        # compute all the audio indices and store them into a DataFrame\n",
    "        # dB_threshold and rejectDuration are used to select audio events.\n",
    "        df_audio_ind = features.all_temporal_alpha_indices(\n",
    "            wave, fs,\n",
    "            mode=CONFIG['mode_env'],\n",
    "            Nt=CONFIG['Nt'],\n",
    "            gain=CONFIG['gain'],\n",
    "            sensibility=CONFIG['sensibility'],\n",
    "            Vadc=CONFIG['sensibility'],\n",
    "            dt=CONFIG['deltaT'],\n",
    "            dB_threshold=CONFIG['dB_threshold'],\n",
    "            rejectDuration=CONFIG['reject_duration'],\n",
    "            verbose=VERBOSE,\n",
    "            display=False\n",
    "            )\n",
    "\n",
    "        # Test if the audio clip\n",
    "        if ((wave.max() >= 0.99) or (wave.min() <= -0.99)):\n",
    "            clip = 1\n",
    "        else:\n",
    "            clip = 0\n",
    "            \n",
    "        df_audio_ind.insert(\n",
    "            loc=0, \n",
    "            column='clipping', \n",
    "            value=clip\n",
    "            )\n",
    "        \n",
    "        df_audio_ind.insert(\n",
    "            loc=1, \n",
    "            column='audio_duration', \n",
    "            value=len(wave) / fs /60\n",
    "            )\n",
    "\n",
    "        \"\"\" ==================================================================\n",
    "                        Computation in the frequency domain \n",
    "        ===================================================================\"\"\"\n",
    "\n",
    "        # Compute the Power Spectrogram Density (PSD) : Sxx_power\n",
    "        Sxx_power, tn, fn, ext = sound.spectrogram(\n",
    "            wave,fs,\n",
    "            window=CONFIG['window'],\n",
    "            nperseg=CONFIG['n_fft'],\n",
    "            noverlap=CONFIG['hop_length'],\n",
    "            verbose=VERBOSE,\n",
    "            display=False,\n",
    "            savefig=None)\n",
    "\n",
    "        # compute all the spectral indices and store them into a DataFrame\n",
    "        # flim_low, flim_mid, flim_hi corresponds to the frequency limits in Hz\n",
    "        # that are required to compute somes indices (i.e. NDSI)\n",
    "        # if R_compatible is set to 'soundecology', then the output is similar to\n",
    "        # soundecology R package.\n",
    "        df_spec_ind, _ = features.all_spectral_alpha_indices(\n",
    "            Sxx_power,\n",
    "            tn, fn,\n",
    "            flim_low=CONFIG['flim_low'],\n",
    "            flim_mid=CONFIG['flim_mid'],\n",
    "            flim_hi=CONFIG['flim_hi'],\n",
    "            R_compatible='soundecology',\n",
    "            seed_level=CONFIG['seed_level'], \n",
    "            low_level=CONFIG['low_level'], \n",
    "            fusion_rois=CONFIG['fusion_rois'],\n",
    "            remove_rois_flim_min = CONFIG['remove_rois_flim_min'],\n",
    "            remove_rois_flim_max = CONFIG['remove_rois_flim_max'],\n",
    "            remove_rain = CONFIG['remove_rain'],\n",
    "            min_event_duration=CONFIG['min_event_duration'], \n",
    "            max_event_duration=CONFIG['max_event_duration'], \n",
    "            min_freq_bw=CONFIG['min_freq_bw'], \n",
    "            max_freq_bw=CONFIG['max_freq_bw'], \n",
    "            max_ratio_xy = CONFIG['max_ratio_xy'],\n",
    "            verbose=VERBOSE,\n",
    "            display=False)\n",
    "\n",
    "        \"\"\" ===================================================================\n",
    "                        Create a dataframe \n",
    "        ====================================================================\"\"\"        \n",
    "        # add scalar indices into the df_indices dataframe\n",
    "        df_indices = pd.concat([df_audio_ind,\n",
    "                                df_spec_ind], axis=1)\n",
    "\n",
    "        # add date and audio_path\n",
    "        df_indices.insert(0, 'Date', date_time)\n",
    "        df_indices.insert(1, 'file', audio_full_filename)\n",
    "    \n",
    "    except:\n",
    "        # create a new dataframe with the column Date and file\n",
    "        df_indices = pd.DataFrame({'Date': [date_time], 'fullfilename': [audio_full_filename], 'file': [file]})\n",
    "\n",
    "    return df_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process the training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"==============================================================================\n",
    "    options             \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "PROCESS_DATA = True\n",
    "SAVE = True\n",
    "DISPLAY = True\n",
    "VERBOSE = False\n",
    "CONFIG = cfg.load_config('config_publication.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset wabad is being processed...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1677 files will be processed'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi cpu indices calculation...: 100%|██████████| 1677/1677 [08:57<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 537.6 seconds\n",
      "The number of audio files that failed to be processes is 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "597ede4f-f9a4-445f-bc7e-269449f80f68",
       "rows": [],
       "shape": {
        "columns": 0,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"==============================================================================\n",
    "    Main loop to process all 1-min soundscapes\n",
    "    ------------------------------------------\n",
    "\n",
    "    Summary of the steps:\n",
    "    ---------------------\n",
    "    - for each dataset in the configuration file:\n",
    "        - prepare the configuration for the dataset\n",
    "        - parse a directory in order to get a df with date and fullfilename\n",
    "        - Multi CPU processing to compute acoustic indices for each audio file\n",
    "        - save the dataframe with all indices\n",
    "        \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "if PROCESS_DATA :\n",
    "\n",
    "    for DATASET in CONFIG['datasets']:\n",
    "\n",
    "        \"\"\" ===========================================================================\n",
    "                        Prepare the configuration for the dataset\n",
    "        ============================================================================\"\"\"\n",
    "        \n",
    "        # test if audio_extension exists in the dataset configuration\n",
    "        if 'audio_extension' not in DATASET.keys():\n",
    "            DATASET['audio_extension'] = CONFIG['audio_extension']\n",
    "\n",
    "        # display the dataset name\n",
    "        display(f'Dataset {DATASET[\"name\"]} is being processed...')\n",
    "        # parse a directory in order to get a df with date and fullfilename\n",
    "        df = util.date_parser(\n",
    "                        datadir=DATASET['path'], \n",
    "                        dateformat=DATASET['datetime_format'], \n",
    "                        extension=DATASET['audio_extension'],\n",
    "                        verbose=False)\n",
    "        # Date is used as index. Reset the index in order to get back Date as column\n",
    "        df.reset_index(inplace = True)\n",
    "        # number of files to process\n",
    "        display('{} files will be processed'.format(len(df)))\n",
    "    \n",
    "        \"\"\" ===========================================================================\n",
    "                        Multi CPU\n",
    "        ============================================================================\"\"\"\n",
    "        # At least 2 CPUs will be used in parallel and the files to process will be \n",
    "        # distributed on each CPU depending on their availability. This will speed up\n",
    "        # the process.\n",
    "\n",
    "        # create an empty dataframe. It will contain all indices for each\n",
    "        # audio file in the directory\n",
    "        df_indices = pd.DataFrame()\n",
    "\n",
    "        # create an empty dataframe. It will contain files that failed\n",
    "        df_failed = pd.DataFrame()\n",
    "\n",
    "        # Number of CPU used for the calculation. \n",
    "        nb_cpu = np.max([2, os.cpu_count()])\n",
    "\n",
    "        tic = time.perf_counter()\n",
    "        # Multicpu process\n",
    "        with tqdm(total=len(df), desc=\"multi cpu indices calculation...\") as pbar:\n",
    "            with futures.ProcessPoolExecutor(max_workers=nb_cpu-1) as pool:\n",
    "                # give the function to map on several CPUs as well its arguments as \n",
    "                # as list\n",
    "                for df_indices_temp in pool.map(\n",
    "                        single_file_processing, \n",
    "                        df[\"file\"].to_list(), \n",
    "                        df[\"Date\"].to_list()\n",
    "                        ):\n",
    "                    pbar.update(1)\n",
    "                    # test the number of columns. If only two, the process failed for the audio file\n",
    "                    if len(df_indices_temp.columns) == 3:\n",
    "                        df_failed = pd.concat([df_failed, df_indices_temp], axis=0)\n",
    "                    else :\n",
    "                        df_indices = pd.concat([df_indices, df_indices_temp], axis=0)\n",
    "        \n",
    "        df_indices.set_index('Date', inplace=True)\n",
    "        \n",
    "        toc = time.perf_counter()\n",
    "        \n",
    "        # time duration of the process\n",
    "        multicpu_duration = toc - tic\n",
    "\n",
    "        print(f\"Elapsed time is {multicpu_duration:0.1f} seconds\")\n",
    "\n",
    "        # display the files that failed to be processed (df_failed)\n",
    "        print(f\"The number of audio files that failed to be processes is {len(df_failed)}\")\n",
    "        display(df_failed)\n",
    "\n",
    "        if SAVE == True:\n",
    "            # save df_indices\n",
    "            df_indices.to_csv(\n",
    "                            path_or_buf=os.path.join(\n",
    "                                                CONFIG['save_dir'], \n",
    "                                                'indices_'+DATASET['name']+'_BW'+str(DATASET['flim_min'])+'Hz_'+str(DATASET['flim_max'])+'Hz_'+str(CONFIG['seed_level'])+'db'+'.csv'), \n",
    "                            sep=',', \n",
    "                            mode='w', \n",
    "                            header=True, \n",
    "                            index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process WABAD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"==============================================================================\n",
    "    options             \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "PROCESS_DATA = True\n",
    "SAVE = True\n",
    "DISPLAY = True\n",
    "VERBOSE = False\n",
    "CONFIG = cfg.load_config('config_publication_wabad.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"==============================================================================\n",
    "    Main loop to process all 1-min soundscapes\n",
    "    ------------------------------------------\n",
    "\n",
    "    Summary of the steps:\n",
    "    ---------------------\n",
    "    - for each dataset in the configuration file:\n",
    "        - prepare the configuration for the dataset\n",
    "        - parse a directory in order to get a df with date and fullfilename\n",
    "        - Multi CPU processing to compute acoustic indices for each audio file\n",
    "        - save the dataframe with all indices\n",
    "        \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "if PROCESS_DATA :\n",
    "\n",
    "    for DATASET in CONFIG['datasets']:\n",
    "\n",
    "        \"\"\" ===========================================================================\n",
    "                        Prepare the configuration for the dataset\n",
    "        ============================================================================\"\"\"\n",
    "        \n",
    "        # test if audio_extension exists in the dataset configuration\n",
    "        if 'audio_extension' not in DATASET.keys():\n",
    "            DATASET['audio_extension'] = CONFIG['audio_extension']\n",
    "\n",
    "        # display the dataset name\n",
    "        display(f'Dataset {DATASET[\"name\"]} is being processed...')\n",
    "        # parse a directory in order to get a df with date and fullfilename\n",
    "        df = util.date_parser(\n",
    "                        datadir=DATASET['path'], \n",
    "                        dateformat=DATASET['datetime_format'], \n",
    "                        extension=DATASET['audio_extension'],\n",
    "                        verbose=False)\n",
    "        # Date is used as index. Reset the index in order to get back Date as column\n",
    "        df.reset_index(inplace = True)\n",
    "        # number of files to process\n",
    "        display('{} files will be processed'.format(len(df)))\n",
    "    \n",
    "        \"\"\" ===========================================================================\n",
    "                        Multi CPU\n",
    "        ============================================================================\"\"\"\n",
    "        # At least 2 CPUs will be used in parallel and the files to process will be \n",
    "        # distributed on each CPU depending on their availability. This will speed up\n",
    "        # the process.\n",
    "\n",
    "        # create an empty dataframe. It will contain all indices for each\n",
    "        # audio file in the directory\n",
    "        df_indices = pd.DataFrame()\n",
    "\n",
    "        # create an empty dataframe. It will contain files that failed\n",
    "        df_failed = pd.DataFrame()\n",
    "\n",
    "        # Number of CPU used for the calculation. \n",
    "        nb_cpu = np.max([2, os.cpu_count()])\n",
    "\n",
    "        tic = time.perf_counter()\n",
    "        # Multicpu process\n",
    "        with tqdm(total=len(df), desc=\"multi cpu indices calculation...\") as pbar:\n",
    "            with futures.ProcessPoolExecutor(max_workers=nb_cpu-1) as pool:\n",
    "                # give the function to map on several CPUs as well its arguments as \n",
    "                # as list\n",
    "                for df_indices_temp in pool.map(\n",
    "                        single_file_processing, \n",
    "                        df[\"file\"].to_list(), \n",
    "                        df[\"Date\"].to_list()\n",
    "                        ):\n",
    "                    pbar.update(1)\n",
    "                    # test the number of columns. If only two, the process failed for the audio file\n",
    "                    if len(df_indices_temp.columns) == 3:\n",
    "                        df_failed = pd.concat([df_failed, df_indices_temp], axis=0)\n",
    "                    else :\n",
    "                        df_indices = pd.concat([df_indices, df_indices_temp], axis=0)\n",
    "        \n",
    "        df_indices.set_index('Date', inplace=True)\n",
    "        \n",
    "        toc = time.perf_counter()\n",
    "        \n",
    "        # time duration of the process\n",
    "        multicpu_duration = toc - tic\n",
    "\n",
    "        print(f\"Elapsed time is {multicpu_duration:0.1f} seconds\")\n",
    "\n",
    "        # display the files that failed to be processed (df_failed)\n",
    "        print(f\"The number of audio files that failed to be processes is {len(df_failed)}\")\n",
    "        display(df_failed)\n",
    "\n",
    "        if SAVE == True:\n",
    "            # save df_indices\n",
    "            df_indices.to_csv(\n",
    "                            path_or_buf=os.path.join(\n",
    "                                                CONFIG['save_dir'], \n",
    "                                                'indices_'+DATASET['name']+'_BW'+str(DATASET['flim_min'])+'Hz_'+str(DATASET['flim_max'])+'Hz_'+str(CONFIG['seed_level'])+'db'+'.csv'), \n",
    "                            sep=',', \n",
    "                            mode='w', \n",
    "                            header=True, \n",
    "                            index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process dB@Risoux dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"==============================================================================\n",
    "    options             \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "PROCESS_DATA = True\n",
    "SAVE = True\n",
    "DISPLAY = True\n",
    "VERBOSE = False\n",
    "CONFIG = cfg.load_config('config_publication_risoux.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset risoux is being processed...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'0 files will be processed'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi cpu indices calculation...: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ear-ml/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'file'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 65\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti cpu indices calculation...\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mnb_cpu\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# give the function to map on several CPUs as well its arguments as \u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# as list\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m df_indices_temp \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m     64\u001b[0m                 single_file_processing, \n\u001b[0;32m---> 65\u001b[0m                 \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_list(), \n\u001b[1;32m     66\u001b[0m                 df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m     67\u001b[0m                 ):\n\u001b[1;32m     68\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;66;03m# test the number of columns. If only two, the process failed for the audio file\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ear-ml/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/ear-ml/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'file'"
     ]
    }
   ],
   "source": [
    "\"\"\"==============================================================================\n",
    "    Main loop to process all 1-min soundscapes\n",
    "    ------------------------------------------\n",
    "\n",
    "    Summary of the steps:\n",
    "    ---------------------\n",
    "    - for each dataset in the configuration file:\n",
    "        - prepare the configuration for the dataset\n",
    "        - parse a directory in order to get a df with date and fullfilename\n",
    "        - Multi CPU processing to compute acoustic indices for each audio file\n",
    "        - save the dataframe with all indices\n",
    "        \n",
    "==============================================================================\"\"\"\n",
    "\n",
    "if PROCESS_DATA :\n",
    "\n",
    "    for DATASET in CONFIG['datasets']:\n",
    "\n",
    "        \"\"\" ===========================================================================\n",
    "                        Prepare the configuration for the dataset\n",
    "        ============================================================================\"\"\"\n",
    "        \n",
    "        # test if audio_extension exists in the dataset configuration\n",
    "        if 'audio_extension' not in DATASET.keys():\n",
    "            DATASET['audio_extension'] = CONFIG['audio_extension']\n",
    "\n",
    "        # display the dataset name\n",
    "        display(f'Dataset {DATASET[\"name\"]} is being processed...')\n",
    "        # parse a directory in order to get a df with date and fullfilename\n",
    "        df = util.date_parser(\n",
    "                        datadir=DATASET['path'], \n",
    "                        dateformat=DATASET['datetime_format'], \n",
    "                        extension=DATASET['audio_extension'],\n",
    "                        verbose=False)\n",
    "        # Date is used as index. Reset the index in order to get back Date as column\n",
    "        df.reset_index(inplace = True)\n",
    "        # number of files to process\n",
    "        display('{} files will be processed'.format(len(df)))\n",
    "    \n",
    "        \"\"\" ===========================================================================\n",
    "                        Multi CPU\n",
    "        ============================================================================\"\"\"\n",
    "        # At least 2 CPUs will be used in parallel and the files to process will be \n",
    "        # distributed on each CPU depending on their availability. This will speed up\n",
    "        # the process.\n",
    "\n",
    "        # create an empty dataframe. It will contain all indices for each\n",
    "        # audio file in the directory\n",
    "        df_indices = pd.DataFrame()\n",
    "\n",
    "        # create an empty dataframe. It will contain files that failed\n",
    "        df_failed = pd.DataFrame()\n",
    "\n",
    "        # Number of CPU used for the calculation. \n",
    "        nb_cpu = np.max([2, os.cpu_count()])\n",
    "\n",
    "        tic = time.perf_counter()\n",
    "        # Multicpu process\n",
    "        with tqdm(total=len(df), desc=\"multi cpu indices calculation...\") as pbar:\n",
    "            with futures.ProcessPoolExecutor(max_workers=nb_cpu-1) as pool:\n",
    "                # give the function to map on several CPUs as well its arguments as \n",
    "                # as list\n",
    "                for df_indices_temp in pool.map(\n",
    "                        single_file_processing, \n",
    "                        df[\"file\"].to_list(), \n",
    "                        df[\"Date\"].to_list()\n",
    "                        ):\n",
    "                    pbar.update(1)\n",
    "                    # test the number of columns. If only two, the process failed for the audio file\n",
    "                    if len(df_indices_temp.columns) == 3:\n",
    "                        df_failed = pd.concat([df_failed, df_indices_temp], axis=0)\n",
    "                    else :\n",
    "                        df_indices = pd.concat([df_indices, df_indices_temp], axis=0)\n",
    "        \n",
    "        df_indices.set_index('Date', inplace=True)\n",
    "        \n",
    "        toc = time.perf_counter()\n",
    "        \n",
    "        # time duration of the process\n",
    "        multicpu_duration = toc - tic\n",
    "\n",
    "        print(f\"Elapsed time is {multicpu_duration:0.1f} seconds\")\n",
    "\n",
    "        # display the files that failed to be processed (df_failed)\n",
    "        print(f\"The number of audio files that failed to be processes is {len(df_failed)}\")\n",
    "        display(df_failed)\n",
    "\n",
    "        if SAVE == True:\n",
    "            # save df_indices\n",
    "            df_indices.to_csv(\n",
    "                            path_or_buf=os.path.join(\n",
    "                                                CONFIG['save_dir'], \n",
    "                                                'indices_'+DATASET['name']+'_BW'+str(DATASET['flim_min'])+'Hz_'+str(DATASET['flim_max'])+'Hz_'+str(CONFIG['seed_level'])+'db'+'.csv'), \n",
    "                            sep=',', \n",
    "                            mode='w', \n",
    "                            header=True, \n",
    "                            index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ear-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
