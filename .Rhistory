alternative = "two.sided"))
plot(puissance)
grippe<-matrix(c(34,50,23,61),2)
dimnames(grippe) <- list(c("homme","femme") ,c("malade","non malade"))
print(grippe)
prop.test(grippe, alternative="two.sided")
prop.test(c(34,50),c(57,111),correct=T)
# Calcul de l'effet taille h pour 2 proportions (package pwr)
h<-ES.h(0.60,0.45)
# Calcul de la puissance (package pwr)
(puissance <- pwr.2p2n.test(h, n1=57,n2=111,
sig.level=0.05,
alternative="two.sided"))
plot(puissance)
transfotitanic <- data.frame(Titanic)
# On charge le package reshape pour modifier les
#donnees avec la fonction untable
library(reshape)
titanic <- data.frame(untable(transfotitanic[,c(1,2,3,4)],
num=transfotitanic[,5]))
# creation du tableau de contingence
# verifier qu'on a bien au moins 5 samples par condition
tabletest <- table(titanic$Survived,titanic$Class)
(test <- chisq.test(tabletest))
test$observed
install.packages("IRkernel")
install.packages("corrplot")
taille = [196, 207]
taille = [196; 207]
taille = cbind(196, 207)
mean(taille)
taille = cbind(196, 207, 193, 187, 231, 207, 175, 185, 251, 157, 178, 207)
mean(taille)
median(taille)
std(taille)
sd(taille)
taille = cbind(196, 207, 193, 187, 231, 207, 175, 185, 251, 187, 178, 207)
mean(taille)
median(taille)
sd(taille)
1.960*28/7.071
1.960*28/sqrt(42)
# Install and load the 'readr' package for efficient CSV reading
install.packages("readr")
library(readr)
# Read the CSV file into a data frame
my_data <- read_csv("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all")
# Read the CSV file into a data frame
my_data <- read_csv("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all.csv")
library(readr)
# Read the CSV file into a data frame
my_data <- read_csv("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all.csv")
# View the first few rows of the data
head(my_data)
# View the first few rows of the data
head(my_data)
read_csv?
?read_csv
# Read the CSV file into a data frame
my_data <- read_csv2("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all.csv")
# View the first few rows of the data
head(my_data)
View(my_data)
View(my_data)
# Read the CSV file into a data frame
my_data <- read_csv("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all.csv")
View(my_data)
?read_csv2
# Read the CSV file into a data frame
my_data <- read_csv2("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all.csv", delim=';')
# Read the CSV file into a data frame
my_data <- read_csv("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all.csv", delim=';')
# Read the CSV file into a data frame
my_data <- read_csv("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all.csv", delim=";")
# Read the CSV file into a data frame
my_data <- read_csv2("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all.csv")
View(my_data)
View(my_data)
# Read the CSV file into a data frame
my_data <- read_csv2("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/clusters_combined_all.csv")
# View the first few rows of the data
head(my_data)
View(my_data)
View(my_data)
data$features
my_data$features
my_data$features[1]
# Read the CSV file into a data frame
my_data <- read_csv2("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/shungo_clusters_combined_all_with_rois.csv")
# Read the CSV file into a data frame
my_data <- read_csv("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/shungo_clusters_combined_all_with_rois.csv")
# View the first few rows of the data
head(my_data)
my_data$features[1]
# Read the CSV file into a data frame
my_data <- read_csv("/media/haupert/LaCie/mes_projets_data/erika_ecuador/Enregistrements_Morpho_projet/rois_clusters/shungo_clusters_combined_all_with_rois.csv",
stringsAsFactors = FALSE)
# View the first few rows of the data
head(my_data)
my_data$features[1]
# Function to convert string to array
str_to_array <- function(x) {
# Remove square brackets and split by space
x <- gsub("\\[|\\]", "", x)
as.numeric(strsplit(x, " ")[[1]])
}
# Apply the function to the desired column (e.g., "my_column")
my_data$my_array <- sapply(my_data$my_column, str_to_array)
# View the first few rows of the data
head(my_data)
my_data$features[1]
# Apply the function to the desired column (e.g., "my_column")
my_data$my_array <- sapply(my_data$features, str_to_array)
# View the first few rows of the data
head(my_data)
my_data$features[1]
my_data$my_array[1]
R.version
if (!require("biostat3")) {
install.packages("biostat3")
library("biostat3")
}
if (!require("tidyr")) {
install.packages("tidyr")
library("tidyr")
}
if (!require("dplyr")) {
install.packages("dplyr")
library("dplyr")
}
if (!require("ggplot2")) {
install.packages("ggplot2")
library("ggplot2")
}
if (!require("cowplot")) {
install.packages("cowplot")
library("cowplot")
}
if (!require("ade4")) {
install.packages("ade4")
library("ade4")
}
if (!require("factoextra")) {
install.packages("factoextra")
library("factoextra")
}
if (!require("sf")) {
install.packages("sf")
library("sf")
}
if (!require("mapview")) {
install.packages("mapview")
library("mapview")
}
if (!require("vegan")) {
install.packages("vegan")
library("vegan")
}
if (!require("ggpubr")) {
install.packages("ggpubr")
library("ggpubr")
}
if (!require("car")) {
install.packages("car")
library("car")
}
if (!require("jtools")) {
install.packages("jtools")
library("jtools")
}
if (!require("visreg")) {
install.packages("visreg")
library("visreg")
}
if (!require("arm")) {
install.packages("arm")
library("arm")
}
if (!require("questionr")) {
install.packages("questionr")
library("questionr")
}
if (!require("ggeffects")) {
install.packages("ggeffects")
library("ggeffects")
}
if (!require("MASS")) {
install.packages("MASS")
library("MASS")
}
if (!require("corrplot")) {
install.packages("corrplot")
library("corrplot")
}
if (!require("mgcv")) {
install.packages("mgcv")
library("mgcv")
}
if (!require("polynom")) {
install.packages("polynom")
library("polynom")
}
if (!require("biostat3")) {
install.packages("biostat3")
library("biostat3")
}
if (!require("tidyr")) {
install.packages("tidyr")
library("tidyr")
}
if (!require("dplyr")) {
install.packages("dplyr")
library("dplyr")
}
if (!require("ggplot2")) {
install.packages("ggplot2")
library("ggplot2")
}
if (!require("cowplot")) {
install.packages("cowplot")
library("cowplot")
}
if (!require("ade4")) {
install.packages("ade4")
library("ade4")
}
if (!require("factoextra")) {
install.packages("factoextra")
library("factoextra")
}
if (!require("sf")) {
install.packages("sf")
library("sf")
}
if (!require("mapview")) {
install.packages("mapview")
library("mapview")
}
if (!require("vegan")) {
install.packages("vegan")
library("vegan")
}
if (!require("ggpubr")) {
install.packages("ggpubr")
library("ggpubr")
}
if (!require("car")) {
install.packages("car")
library("car")
}
if (!require("jtools")) {
install.packages("jtools")
library("jtools")
}
if (!require("visreg")) {
install.packages("visreg")
library("visreg")
}
if (!require("arm")) {
install.packages("arm")
library("arm")
}
if (!require("questionr")) {
install.packages("questionr")
library("questionr")
}
if (!require("ggeffects")) {
install.packages("ggeffects")
library("ggeffects")
}
if (!require("MASS")) {
install.packages("MASS")
library("MASS")
}
if (!require("corrplot")) {
install.packages("corrplot")
library("corrplot")
}
if (!require("mgcv")) {
install.packages("mgcv")
library("mgcv")
}
if (!require("polynom")) {
install.packages("polynom")
library("polynom")
}
if (!require("biostat3")) {
install.packages("biostat3")
library("biostat3")
}
# Use the convert_ipynb() function
convert_ipynb(input = input_file, output = output_file)
output_file <- "/media/haupert/data/mes_projets/07_nroi/nROI_publication.git/notebooks/R_01_correlation_indices.Rmd"
# Install the knitr package if you haven't already
install.packages("knitr")
# Use the knit() function from knitr to convert the .ipynb file
knit(input = input_file, output = output_file)
# Construct the command for jupyter nbconvert
command <- paste0("jupyter nbconvert --to rmarkdown ", shQuote(input_file), " --output ", shQuote(output_file))
# Specify the input and output file paths
input_file <- "/media/haupert/data/mes_projets/07_nroi/nROI_publication.git/notebooks/R_01_correlation_indices.ipynb"
print(exit_status)
cat("Data dimensions after cleaning:", nrow(data_clean), "rows,", ncol(data_clean), "columns\n")
# =============================================================================
# Statistical Modeling with Generalized Linear Mixed Models (GLMM) in R
# Updated: January 2026
# =============================================================================
# Clear workspace
rm(list = ls())
# set wd to the script location
setwd("./")
# Load required libraries
# =============================================================================
if (!require("glmmTMB")) install.packages("glmmTMB")
if (!require("DHARMa")) install.packages("DHARMa")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("dplyr")) install.packages("dplyr")
if (!require("performance")) install.packages("performance")
if (!require("DescTools")) install.packages("DescTools")
library(glmmTMB) # Generalized linear mixed models with various distributions
library(DHARMa) # Residual diagnostics for GLMMs
library(ggplot2) # Plotting
library(dplyr) # Data manipulation
library(performance) # Model performance metrics
library(DescTools) # For CCC calculation
# Set options
# =============================================================================
options(contrasts = c("contr.sum", "contr.poly")) # Type III sum of squares
options(width = 120)
# Data loading and preparation
# =============================================================================
cat("Loading and preparing data...\n")
# Load the data
data_path <- "./results/train_dataset_for_statistical_modeling_in_R.csv"
if (!file.exists(data_path)) {
stop("Data file not found. Please check the path: ", data_path)
}
setwd("/media/haupert/data/mes_projets/07_nroi/nROI_publication_test_before_revision_v1.git/haupert_acoustic_indices_2025/notebooks")
setwd("/media/haupert/data/mes_projets/07_nroi/nROI_publication_test_before_revision_v1.git/haupert_acoustic_indices_2025")
# =============================================================================
# Statistical Modeling with Generalized Linear Mixed Models (GLMM) in R
# Updated: January 2026
# =============================================================================
# Clear workspace
rm(list = ls())
# set wd to the script location
setwd("./")
# Load required libraries
# =============================================================================
if (!require("glmmTMB")) install.packages("glmmTMB")
if (!require("DHARMa")) install.packages("DHARMa")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("dplyr")) install.packages("dplyr")
if (!require("performance")) install.packages("performance")
if (!require("DescTools")) install.packages("DescTools")
library(glmmTMB) # Generalized linear mixed models with various distributions
library(DHARMa) # Residual diagnostics for GLMMs
library(ggplot2) # Plotting
library(dplyr) # Data manipulation
library(performance) # Model performance metrics
library(DescTools) # For CCC calculation
# Set options
# =============================================================================
options(contrasts = c("contr.sum", "contr.poly")) # Type III sum of squares
options(width = 120)
# Data loading and preparation
# =============================================================================
cat("Loading and preparing data...\n")
# Load the data
data_path <- "./results/train_dataset_for_statistical_modeling_in_R.csv"
if (!file.exists(data_path)) {
stop("Data file not found. Please check the path: ", data_path)
}
data <- read.csv(data_path, stringsAsFactors = FALSE)
# Display data structure
cat("Data structure:\n")
str(data)
cat("\nFirst few rows:\n")
head(data)
# Data preprocessing
# =============================================================================
cat("\nData preprocessing...\n")
# Convert categorical variables to factors
data$device_id <- as.factor(data$device_id)
data$site <- as.factor(data$site)
data$habitat <- as.factor(data$habitat)
data$dataset <- as.factor(data$dataset)
# Check for missing values
cat("Missing values per column:\n")
print(colSums(is.na(data)))
# Remove rows with missing values in key variables
data_clean <- data[complete.cases(data[c("species_richness", "nROI", "device_id", "habitat", "dataset")]), ]
cat("Data dimensions after cleaning:", nrow(data_clean), "rows,", ncol(data_clean), "columns\n")
# Aggregate data by site (as in Python code)
# =============================================================================
cat("\nAggregating data by site...\n")
# Average species richness and nROI per site keeping site, habitat, device_id, and dataset
data_agg <- data_clean %>%
group_by(site, habitat, device_id, dataset, LAT, LON) %>%
summarise(
species_richness = mean(species_richness, na.rm = TRUE),
nROI = mean(nROI, na.rm = TRUE),
n_observations = n(),
.groups = "drop"
)
cat("Aggregated data dimensions:", nrow(data_agg), "rows,", ncol(data_agg), "columns\n")
# Summary statistics
cat("\nSummary statistics:\n")
print(summary(data_agg))
# Display data distribution by groups
cat("\nData distribution by groups:\n")
cat("Number of observations per dataset:\n")
print(table(data_agg$dataset))
cat("\nNumber of observations per habitat:\n")
print(table(data_agg$habitat))
cat("\nNumber of observations per device:\n")
print(table(data_agg$device_id))
# Exploratory data analysis
# =============================================================================
cat("\nExploratory Data Analysis...\n")
# Distribution of species richness
p1 <- ggplot(data_agg, aes(x = species_richness)) +
geom_histogram(bins = 20, fill = "skyblue", alpha = 0.7) +
labs(title = "Distribution of Species Richness", x = "Average Species Richness by site", y = "Frequency") +
theme_minimal()
print(p1)
# Distribution of nROI
p1_nroi <- ggplot(data_agg, aes(x = nROI)) +
geom_histogram(bins = 20, fill = "lightgreen", alpha = 0.7) +
labs(title = "Distribution of nROI", x = "Average nROI by site", y = "Frequency") +
theme_minimal()
print(p1_nroi)
# For regression: You can fit a standard Gaussian GLM as below,
# but it will not capture multimodality in the response distribution.
p2 <- ggplot(data_agg, aes(x = nROI, y = species_richness)) +
geom_point(aes(color = habitat), alpha = 0.7) +
geom_smooth(method = "glm", method.args = list(family = gaussian(link = "identity")), se = TRUE) +
labs(title = "Species Richness vs nROI (Gaussian GLM)", x = "nROI", y = "Species Richness") +
theme_minimal() +
facet_wrap(~dataset, scales = "free") +
coord_cartesian(xlim = c(0, 260), ylim = c(0, 8))
print(p2)
# save the plot
# ggsave("./results/species_richness_vs_nROI_by_dataset.png", plot = p2, dpi = 300)
# Relationship between nROI and species richness but by habitat
# Faceted by habitat
p2_habitat <- ggplot(data_agg, aes(x = nROI, y = species_richness)) +
geom_point(aes(color = habitat), alpha = 0.7) +
geom_smooth(method = "glm", method.args = list(family = gaussian(link = "identity")), se = TRUE) +
labs(title = "Species Richness vs nROI by Habitat", x = "nROI", y = "Species Richness") +
theme_minimal() +
facet_wrap(~habitat, scales = "free", ncol = 3) +
coord_cartesian(xlim = c(0, 260), ylim = c(0, 8)) +
theme(legend.position = c(0.82, 0.15))
print(p2_habitat)
# save the plot
# ggsave("./results/species_richness_vs_nROI_by_habitat.png", plot = p2_habitat, dpi = 300)
# Box plots by groups
p3 <- ggplot(data_agg, aes(x = habitat, y = species_richness)) +
geom_boxplot(aes(fill = habitat), alpha = 0.7) +
labs(title = "Species Richness by Habitat", x = "Habitat", y = "Species Richness") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
scale_x_discrete(labels = function(x) gsub("-", "\n", x))
print(p3)
# save the plot
# ggsave("./results/species_richness_barplots_by_habitat.png", plot = p3, dpi = 300)
# Model fitting
# =============================================================================
cat("STATISTICAL MODELING\n")
# Keep habitats with at least 3 observations (n_observations)
data_agg <- data_agg %>%
group_by(habitat) %>%
filter(n() >= 3) %>%
ungroup()
# remove empty habitats
data_agg <- droplevels(data_agg)
# Check distribution of species richness for model selection
cat("Species richness distribution for model selection:\n")
print(summary(data_agg$species_richness))
cat("Variance:", var(data_agg$species_richness), "\n")
cat("Mean:", mean(data_agg$species_richness), "\n")
cat("Variance/Mean ratio:", var(data_agg$species_richness) / mean(data_agg$species_richness), "\n")
# Check if variables are appropriate for different model types
cat("\nData type check AFTER aggregation:\n")
cat("Species richness - integers?", all(data_agg$species_richness == round(data_agg$species_richness), na.rm = TRUE), "\n")
cat("Species richness range:", range(data_agg$species_richness), "\n")
cat("Any zero values?", any(data_agg$species_richness == 0), "\n")
cat("nROI - integers?", all(data_agg$nROI == round(data_agg$nROI), na.rm = TRUE), "\n")
cat("nROI range:", range(data_agg$nROI), "\n")
cat("Any zero values?", any(data_agg$nROI == 0), "\n")
cat("Variance/Mean ratio:", var(data_agg$nROI) / mean(data_agg$nROI), "\n")
# Check is the variance is roughly constant across nROI values (homoscedasticity)
cat("\nChecking homoscedasticity of species richness across nROI values:\n")
model_lm_check <- lm(species_richness ~ nROI, data = data_agg)
par(mfrow = c(1, 2))
plot(model_lm_check, which = 1) # Residuals vs Fitted
plot(model_lm_check, which = 3) # Scale-Location plot
par(mfrow = c(1, 1))
# Look for patterns in residuals: a horizontal band of points indicates homoscedasticity
#-----------------------------------------------------------------------------
# Model base: Baseline model with only the smooth fixed effect
#-----------------------------------------------------------------------------
# Minimal model with only nROI to compare
lm_base <- lm(
species_richness ~ nROI,
data = data_agg
)
# Check model summary and fixed effects p-values
summary(lm_base)
plot(lm_base, pages = 1)
testDispersion(sim_res) # Test for overdispersion
